{"title":"Regression model using random forest","markdown":{"yaml":{"title":"Regression model using random forest","author":"Sai manikanta praneeth perala","editor":"visual","date":"2024-01-06","categories":["code","analysis","mchine learning model","R"],"image":"image.jpg"},"headingText":"Random Forest","containsRefs":false,"markdown":"\n\n\nThe R code demonstrates the construction of a random forest classification model using a synthetic dataset with two features (X1 and X2) and a binary target variable (Y). The model is trained on 80% of the data and tested on the remaining 20%. The random forest consists of 100 trees. \\## INTRODUCTION\n\nThe model accuracy is then evaluated on the test set, yielding an accuracy of 0.5. An accuracy of 0.5 suggests that the model is performing no better than random chance in predicting the binary outcome. In this case, the model is not effectively capturing the underlying patterns in the data, and further exploration, feature engineering, or parameter tuning may be necessary to improve its performance. The scatter plot visually represents the data points and their classification, where the black points correspond to the instances in the test set. The lack of clear separation in the plot indicates the model's struggle in distinguishing between the two classes based on the given features.\n\n```{r, echo=TRUE}\n# Load required libraries\nlibrary(randomForest)\nlibrary(ggplot2)\n\n# Set a seed for reproducibility\nset.seed(123)\n\n# Generate a random dataset with two features (X1 and X2) and a binary target variable (Y)\nn <- 100\ndata <- data.frame(\n  X1 = rnorm(n),\n  X2 = rnorm(n),\n  Y = factor(sample(0:1, n, replace = TRUE))\n)\n\n# Split the dataset into training and testing sets\ntrain_indices <- sample(1:n, 0.8 * n)\ntrain_data <- data[train_indices, ]\ntest_data <- data[-train_indices, ]\n\n# Train a random forest model\nrf_model <- randomForest(Y ~ X1 + X2, data = train_data, ntree = 100)\n\n# Make predictions on the test set\npredictions <- predict(rf_model, newdata = test_data)\n\n# Evaluate model accuracy\naccuracy <- mean(predictions == test_data$Y)\ncat(\"Model Accuracy:\", accuracy, \"\\n\")\n\n# Visualize the random forest results\n# Since we have two features, we can create a scatter plot\nggplot(data, aes(x = X1, y = X2, color = Y)) +\n  geom_point() +\n  geom_point(data = test_data, aes(x = X1, y = X2), color = \"black\", size = 3, alpha = 0.5) +\n  ggtitle(\"Random Forest Classification\") +\n  theme_minimal()\n```\n","srcMarkdownNoYaml":"\n\n# Random Forest\n\nThe R code demonstrates the construction of a random forest classification model using a synthetic dataset with two features (X1 and X2) and a binary target variable (Y). The model is trained on 80% of the data and tested on the remaining 20%. The random forest consists of 100 trees. \\## INTRODUCTION\n\nThe model accuracy is then evaluated on the test set, yielding an accuracy of 0.5. An accuracy of 0.5 suggests that the model is performing no better than random chance in predicting the binary outcome. In this case, the model is not effectively capturing the underlying patterns in the data, and further exploration, feature engineering, or parameter tuning may be necessary to improve its performance. The scatter plot visually represents the data points and their classification, where the black points correspond to the instances in the test set. The lack of clear separation in the plot indicates the model's struggle in distinguishing between the two classes based on the given features.\n\n```{r, echo=TRUE}\n# Load required libraries\nlibrary(randomForest)\nlibrary(ggplot2)\n\n# Set a seed for reproducibility\nset.seed(123)\n\n# Generate a random dataset with two features (X1 and X2) and a binary target variable (Y)\nn <- 100\ndata <- data.frame(\n  X1 = rnorm(n),\n  X2 = rnorm(n),\n  Y = factor(sample(0:1, n, replace = TRUE))\n)\n\n# Split the dataset into training and testing sets\ntrain_indices <- sample(1:n, 0.8 * n)\ntrain_data <- data[train_indices, ]\ntest_data <- data[-train_indices, ]\n\n# Train a random forest model\nrf_model <- randomForest(Y ~ X1 + X2, data = train_data, ntree = 100)\n\n# Make predictions on the test set\npredictions <- predict(rf_model, newdata = test_data)\n\n# Evaluate model accuracy\naccuracy <- mean(predictions == test_data$Y)\ncat(\"Model Accuracy:\", accuracy, \"\\n\")\n\n# Visualize the random forest results\n# Since we have two features, we can create a scatter plot\nggplot(data, aes(x = X1, y = X2, color = Y)) +\n  geom_point() +\n  geom_point(data = test_data, aes(x = X1, y = X2), color = \"black\", size = 3, alpha = 0.5) +\n  ggtitle(\"Random Forest Classification\") +\n  theme_minimal()\n```\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":true,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","highlight-style":"github","output-file":"index.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.3.433","editor":"visual","theme":{"light":"cosmo","dark":["darkly"]},"title-block-banner":true,"title":"Regression model using random forest","author":"Sai manikanta praneeth perala","date":"2024-01-06","categories":["code","analysis","mchine learning model","R"],"image":"image.jpg"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}